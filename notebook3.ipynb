{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\lazy_loader\\__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\lazy_loader\\__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.layers import Input, Dense\n",
    "# from sklearn.preprocessing import Imputer, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for loading audios.\n",
    "\n",
    "os.chdir(\"D:/Projects/Hackathons/AI4D ASR Challenge/quizes/Swahili-Speech-To-Text/data/train/wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Audio Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10',\n",
       "  'audio': array([0.02857866, 0.03156228, 0.02614644, ..., 0.09533662, 0.09504194,\n",
       "         0.05807269], dtype=float32)},\n",
       " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100',\n",
       "  'audio': array([ 0.00458592,  0.0062088 ,  0.00575972, ...,  0.01638122,\n",
       "         -0.00736282, -0.01466544], dtype=float32)},\n",
       " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101',\n",
       "  'audio': array([0.00858414, 0.00945346, 0.00636425, ..., 0.22225821, 0.2822022 ,\n",
       "         0.10905091], dtype=float32)},\n",
       " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102',\n",
       "  'audio': array([-0.01062333, -0.01205456, -0.0101964 , ..., -0.21636732,\n",
       "         -0.2038639 , -0.11033028], dtype=float32)},\n",
       " {'filename': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103',\n",
       "  'audio': array([0.01031982, 0.01360501, 0.01285982, ..., 0.05907759, 0.05388482,\n",
       "         0.02589668], dtype=float32)}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "parent_dir = \"./\"\n",
    "files = os.listdir(parent_dir)\n",
    "for f in files[:1100]:\n",
    "    audio, fs = librosa.load(f\"{f}\")\n",
    "    filename = f.split('.')[0]\n",
    "    row = {'filename': filename, 'audio': audio}\n",
    "    rows.append(row)\n",
    "rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10180"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.02857866, 0.03156228, 0.02614644, ..., 0.09533662, 0.09504194,\n",
       "        0.05807269], dtype=float32),\n",
       " array([ 0.00458592,  0.0062088 ,  0.00575972, ...,  0.01638122,\n",
       "        -0.00736282, -0.01466544], dtype=float32),\n",
       " array([0.00858414, 0.00945346, 0.00636425, ..., 0.22225821, 0.2822022 ,\n",
       "        0.10905091], dtype=float32),\n",
       " array([-0.01062333, -0.01205456, -0.0101964 , ..., -0.21636732,\n",
       "        -0.2038639 , -0.11033028], dtype=float32),\n",
       " array([0.01031982, 0.01360501, 0.01285982, ..., 0.05907759, 0.05388482,\n",
       "        0.02589668], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_audios = []\n",
    "for row in rows:\n",
    "    audio = row['audio']\n",
    "    sample_audios.append(audio)\n",
    "sample_audios[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Csv Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('D:/Projects/Hackathons/AI4D ASR Challenge/quizes/Swahili-Speech-To-Text/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcription</th>\n",
       "      <th>filepath</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
       "      <td>SWH-05-20101106/SWH-05-20101106_16k-emission_s...</td>\n",
       "      <td>16000</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "\n",
       "                                       transcription  \\\n",
       "0             rais wa tanzania jakaya mrisho kikwete   \n",
       "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...   \n",
       "2  inayokutangazia moja kwa moja kutoka jijini da...   \n",
       "3  juma hili bara la afrika limeshuhudia raia wa ...   \n",
       "4    wakipiga kura ya maoni ilikufanya mabadiliko ya   \n",
       "\n",
       "                                            filepath  sample_rate  duration  \n",
       "0  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.14  \n",
       "1  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.10  \n",
       "2  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.65  \n",
       "3  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      3.90  \n",
       "4  SWH-05-20101106/SWH-05-20101106_16k-emission_s...        16000      2.94  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORE OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([['rais wa tanzania jakaya mrisho kikwete']], dtype=object),\n",
       " array([['yanayo andaliwa nami pendo pondo idhaa ya kiswahili']],\n",
       "       dtype=object),\n",
       " array([['inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania']],\n",
       "       dtype=object),\n",
       " array([['juma hili bara la afrika limeshuhudia raia wa nchi za niger']],\n",
       "       dtype=object),\n",
       " array([['wakipiga kura ya maoni ilikufanya mabadiliko ya']], dtype=object)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txts = []\n",
    "for row in rows:\n",
    "    filename = row['filename']\n",
    "    filter = meta_df[meta_df['filename'] == filename]\n",
    "    txt = filter[['transcription']].values\n",
    "    txts.append(txt)\n",
    "\n",
    "txts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = np.array(txts).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_txts = []\n",
    "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
    "for txt in txts:\n",
    "    clean_txt = []\n",
    "    for c in txt:\n",
    "        if c not in alphabets and c != ' ':\n",
    "            continue\n",
    "        clean_txt.append(c)\n",
    "    clean_txt = ''.join(clean_txt)\n",
    "    clean_txts.append(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rais wa tanzania jakaya mrisho kikwete',\n",
       " 'yanayo andaliwa nami pendo pondo idhaa ya kiswahili',\n",
       " 'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania',\n",
       " 'juma hili bara la afrika limeshuhudia raia wa nchi za niger',\n",
       " 'wakipiga kura ya maoni ilikufanya mabadiliko ya']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_txts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'' in clean_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts\n",
       "0             rais wa tanzania jakaya mrisho kikwete\n",
       "1  yanayo andaliwa nami pendo pondo idhaa ya kisw...\n",
       "2  inayokutangazia moja kwa moja kutoka jijini da...\n",
       "3  juma hili bara la afrika limeshuhudia raia wa ...\n",
       "4    wakipiga kura ya maoni ilikufanya mabadiliko ya"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clean_txts)\n",
    "df.columns = ['texts']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([19, 21, 56, 584, 655, 710, 814, 822, 873, 922, 1008], dtype='int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = df[df['texts'] == ''].index\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clean_txts[idxs[-1]]\n",
    "del clean_txts[idxs[-2]]\n",
    "del clean_txts[idxs[-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'' in clean_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sample_audios[idxs[-1]]\n",
    "del sample_audios[idxs[-2]]\n",
    "del sample_audios[idxs[-3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_dict():\n",
    "    alphabet = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
    "    supported = alphabet.split()\n",
    "\n",
    "    char_map = {}\n",
    "    char_map[\"\"] = 0\n",
    "    char_map[\"<SPACE>\"] = 1\n",
    "    idx = 2\n",
    "    for c in supported:\n",
    "        char_map[c] = idx\n",
    "        idx += 1\n",
    "    index_map = {v: k for k, v in char_map.items()}\n",
    "    return char_map, index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map, index_map = character_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '<SPACE>': 1,\n",
       " 'a': 2,\n",
       " 'b': 3,\n",
       " 'c': 4,\n",
       " 'd': 5,\n",
       " 'e': 6,\n",
       " 'f': 7,\n",
       " 'g': 8,\n",
       " 'h': 9,\n",
       " 'i': 10,\n",
       " 'j': 11,\n",
       " 'k': 12,\n",
       " 'l': 13,\n",
       " 'm': 14,\n",
       " 'n': 15,\n",
       " 'o': 16,\n",
       " 'p': 17,\n",
       " 'q': 18,\n",
       " 'r': 19,\n",
       " 's': 20,\n",
       " 't': 21,\n",
       " 'u': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25,\n",
       " 'y': 26,\n",
       " 'z': 27}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_int_sequence(text):\n",
    "    \"\"\" Convert text to an integer sequence \"\"\"\n",
    "    int_sequence = []\n",
    "    for c in text:\n",
    "        if c == ' ':\n",
    "            ch = char_map['<SPACE>']\n",
    "        elif c in alphabets:\n",
    "            ch = char_map[c]\n",
    "        else:\n",
    "            print(c)\n",
    "            print('character not found')\n",
    "            break\n",
    "        int_sequence.append(ch)\n",
    "    return np.array(int_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_sequence_to_text(int_sequence):\n",
    "    \"\"\" Convert an integer sequence to text \"\"\"\n",
    "    textch = []\n",
    "    for c in int_sequence:\n",
    "        ch = index_map[c]\n",
    "        textch.append(ch)\n",
    "    text = ''.join(textch)\n",
    "    text = text.replace('<SPACE>', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, audios, texts, batch_size=32):\n",
    "        self.audios = audios\n",
    "        self.texts = texts\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = int(len(self.audios) // self.batch_size)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.steps*self.batch_size)\n",
    "        # np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[int(index*self.batch_size):int((index+1)*self.batch_size)]\n",
    "    \n",
    "        batch_audios = [self.audios[int(i)] for i in indexes]\n",
    "        batch_texts = [self.texts[int(i)] for i in indexes]\n",
    "        \n",
    "        return  self.data_generation(batch_audios, batch_texts)\n",
    "    \n",
    "    def data_generation(self, batch_audios, batch_texts):\n",
    "\n",
    "        longest_audio = max([len(i) for i in batch_audios])\n",
    "        longest_txt = max([len(i) for i in batch_texts])\n",
    "\n",
    "        audios          = np.zeros([int(self.batch_size), longest_audio], dtype=\"float32\")\n",
    "        txts            = np.zeros([int(self.batch_size), longest_txt], dtype=\"int64\")\n",
    "        audio_length    = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
    "        txt_length      = np.zeros([int(self.batch_size)], dtype=\"int64\")\n",
    "\n",
    "        i = 0\n",
    "        for audio, txt in zip(batch_audios, batch_texts):\n",
    "\n",
    "            txt_len = len(txt)\n",
    "\n",
    "            txt = text_to_int_sequence(txt)\n",
    "       \n",
    "            txts[i,: txt_len] = txt\n",
    "\n",
    "            audio_len = len(audio)\n",
    "\n",
    "            audios[i, :audio_len] = audio\n",
    "\n",
    "            audio_length[i] = audio_len\n",
    "            txt_length[i] = txt_len\n",
    "\n",
    "            i+=1          \n",
    "            \n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "        inputs = {\n",
    "                    'the_input':    tf.convert_to_tensor(audios), \n",
    "                    'the_labels':   tf.convert_to_tensor(txts), \n",
    "                    'input_length': tf.convert_to_tensor(audio_length), \n",
    "                    'label_length': tf.convert_to_tensor(txt_length)\n",
    "                }\n",
    "        return (inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGenerator(sample_audios, clean_txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'the_input': <tf.Tensor: shape=(32, 135387), dtype=float32, numpy=\n",
       "  array([[ 5.6196041e-05,  1.3418791e-04,  2.4972850e-04, ...,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "         [-7.0419593e-04,  1.0930605e-03,  2.0159236e-03, ...,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "         [ 2.3599446e-03,  5.4497039e-03,  7.7096177e-03, ...,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "         ...,\n",
       "         [-5.7262392e-04, -1.4827361e-03, -1.2523080e-03, ...,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "         [ 1.1664884e-02,  9.6330661e-03,  1.0384502e-02, ...,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "         [ 4.2224964e-04,  3.1806174e-04,  1.2545670e-04, ...,\n",
       "           0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>,\n",
       "  'the_labels': <tf.Tensor: shape=(32, 122), dtype=int64, numpy=\n",
       "  array([[16,  7, 10, ...,  0,  0,  0],\n",
       "         [14, 10, 14, ...,  0,  0,  0],\n",
       "         [10, 14,  6, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [22, 11,  2, ...,  0,  0,  0],\n",
       "         [ 3, 22, 19, ..., 10, 15, 10],\n",
       "         [26,  2, 13, ...,  0,  0,  0]], dtype=int64)>,\n",
       "  'input_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "  array([ 67914,  71663, 105840,  65048, 135387,  95918,  55566,  49391,\n",
       "          59756,  59976,  69017,  85113, 102533,  48069,  49391,  97020,\n",
       "          76513,  62181,  49833,  57110,  69899,  76073,  59975, 110030,\n",
       "          62843,  54023,  81365,  59315, 103856, 123039, 125466,  75632],\n",
       "        dtype=int64)>,\n",
       "  'label_length': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "  array([ 55,  42,  84,  44, 100,  75,  42,  30,  34,  30,  53,  59,  37,\n",
       "          36,  29,  94,  55,  45,  40,  56,  67,  69,  40,  81,  41,  39,\n",
       "          64,  50, 116, 110, 122,  54], dtype=int64)>},\n",
       " {'ctc': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = dg[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 102), dtype=int64, numpy=\n",
       "array([[19,  2, 10, ...,  0,  0,  0],\n",
       "       [26,  2, 15, ...,  0,  0,  0],\n",
       "       [10, 15,  2, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [13,  2, 12, ...,  0,  0,  0],\n",
       "       [20, 10, 24, ...,  0,  0,  0],\n",
       "       [12, 22, 13, ...,  0,  0,  0]], dtype=int64)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['the_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 128993), dtype=float32, numpy=\n",
       "array([[ 0.02857866,  0.03156228,  0.02614644, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.00458592,  0.0062088 ,  0.00575972, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.00858414,  0.00945346,  0.00636425, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.01875213,  0.02185869,  0.01020589, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.09314458,  0.11669447,  0.11490583, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.01866547, -0.02101425, -0.01500233, ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['the_input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_lengths_lambda_func(args):\n",
    "    input_length = args\n",
    "    return tf.cast(tf.math.floor(input_length/hop_size)-1, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ctc_loss(model_builder):\n",
    "    the_labels      = Input(name='the_labels',      shape=(None,), dtype='float32')\n",
    "    input_lengths   = Input(name='input_length',    shape=(1,), dtype='float32')\n",
    "    label_lengths   = Input(name='label_length',    shape=(1,), dtype='float32')\n",
    "\n",
    "    input_lengths2 = Lambda(input_lengths_lambda_func)(input_lengths)\n",
    "    if model_builder.output_length:\n",
    "         output_lengths  = Lambda(model_builder.output_length)(input_lengths2)\n",
    "    else:\n",
    "         output_lengths  = input_lengths2\n",
    "    \n",
    "    # CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([model_builder.output, the_labels, output_lengths, label_lengths])\n",
    "    model = Model( inputs=[model_builder.input, the_labels, input_lengths, label_lengths],  outputs=loss_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BUILDING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogMelspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
    "                 f_min=0.0, f_max=None, **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_mels = n_mels\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.n_mels,\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\n",
    "            sample_rate=self.sample_rate,\n",
    "            lower_edge_hertz=self.f_min,\n",
    "            upper_edge_hertz=self.f_max)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        \"\"\"Forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
    "            A Batch of mono waveforms.\n",
    "        Returns\n",
    "        -------\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
    "            The corresponding batch of log-mel-spectrograms\n",
    "        \"\"\"\n",
    "        def _tf_log10(x):\n",
    "            numerator = tf.math.log(x)\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "            return numerator / denominator\n",
    "\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
    "            \"\"\"\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "            \"\"\"\n",
    "            ref_value = tf.reduce_max(magnitude)\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "            return log_spec\n",
    "\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
    "                                     self.mel_filterbank)\n",
    "\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
    "\n",
    "        # add channel dimension\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
    "\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'n_mels': self.n_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessin_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\n",
    "\n",
    "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
    "    featLayer = LogMelSpectrogram(\n",
    "        fft_size=fft_size,\n",
    "        hop_size=frame_step,\n",
    "        n_mels=n_mels,\n",
    "        \n",
    "        sample_rate=sample_rate,\n",
    "        f_min=0.0,\n",
    "        \n",
    "        f_max=int(sample_rate / 2)\n",
    "    )(input_data)\n",
    "    \n",
    "    x = BatchNormalization()(featLayer)\n",
    "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rnn_model(input_dim, output_dim=224):\n",
    "\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    simp_rnn = GRU(output_dim, return_sequences=True,\n",
    "                   implementation=2, name='rnn')(input_data)\n",
    "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
    "    model = Model(inputs=input_data, outputs=y_pred, name=\"simple_rnn_model\")\n",
    "    model.output_length = lambda x: x\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BidirectionalRNN(input_dim, rnn_layers=2, units=400, drop_out=0.5, act='tanh', output_dim=224):\n",
    "\n",
    "    input_data = Input(name='the_input', shape=(\n",
    "        None, input_dim))\n",
    "\n",
    "    x = Bidirectional(LSTM(units,  activation=act,\n",
    "                      return_sequences=True, implementation=2))(input_data)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(drop_out)(x)\n",
    "\n",
    "    for i in range(rnn_layers - 2):\n",
    "        x = Bidirectional(\n",
    "            LSTM(units, activation=act, return_sequences=True))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(drop_out)(x)\n",
    "\n",
    "    x = Bidirectional(LSTM(units,  activation=act,\n",
    "                      return_sequences=True, implementation=2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(drop_out)(x)\n",
    "\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(x)\n",
    "\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=y_pred, name=\"BidirectionalRNN\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_rnn(n_mels, output_dim=224, rnn_layers=4, units=400, drop_out=0.5, act='tanh'):\n",
    "\n",
    "    input_data = Input(name='the_input', shape=(None, n_mels, 1))\n",
    "\n",
    "    y = Conv2D(32, (3, 3), padding='same')(input_data)  # was 32\n",
    "    y = Activation('relu')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    x = MaxPooling2D((1, 2))(y)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(y)  # was 32\n",
    "    x = Activation('relu')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    x = MaxPooling2D((1, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    x = MaxPooling2D((1, 2))(x)\n",
    "\n",
    "    x = Dense(128)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dense(32)(x)\n",
    "\n",
    "    x = Reshape((-1, x.shape[-1] * x.shape[-2]))(x)\n",
    "\n",
    "    for i in range(rnn_layers):\n",
    "        x = Bidirectional(\n",
    "            LSTM(units, activation=act, return_sequences=True))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(drop_out)(x)\n",
    "\n",
    "    bn_rnn = BatchNormalization()(x)\n",
    "\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(bn_rnn)\n",
    "\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=y_pred, name=\"custom_model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_builder, \n",
    "          data_gen,\n",
    "          epochs, \n",
    "          verbose=1,\n",
    "          optimizer=tf.keras.optimizers.legacy.SGD(learning_rate=0.002, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
    "          ):    \n",
    "              \n",
    "    model = add_ctc_loss(model_builder)\n",
    "\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "    print(model.summary())\n",
    "\n",
    "    # add checkpointer\n",
    "    checkpointer = ModelCheckpoint(filepath='models/cnn_rnn.h5', verbose=1)\n",
    "    early_stopping = EarlyStopping( monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "    hist = model.fit_generator(generator=data_gen,\n",
    "                               epochs=epochs,\n",
    "                               callbacks=[checkpointer, early_stopping], \n",
    "                               verbose=verbose, \n",
    "                               use_multiprocessing=False)\n",
    "    \n",
    "    # save model loss\n",
    "    with open('/models/cnn_rnn.pickle', 'wb') as f:\n",
    "        pickle.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_rate = 22050\n",
    "fft_size = 1024\n",
    "frame_step = 512\n",
    "n_mels = 128\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "data_len = len(clean_txts)\n",
    "output_dim = len(char_map) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGenerator(sample_audios, clean_txts, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"preprocessin_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, None)]            0         \n",
      "                                                                 \n",
      " log_mel_spectrogram (LogMe  (None, None, 128, 1)      0         \n",
      " lSpectrogram)                                                   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, None, 128, 1)      4         \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4 (16.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 2 (8.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "preprocess_model = preprocessin_model(sample_rate, fft_size, frame_step, n_mels)\n",
    "preprocess_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 128, 1)]    0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, 128, 32)     320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, 128, 32)     0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, None, 128, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, 128, 64)     18496     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, 128, 64)     0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, 64, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, 64, 128)     73856     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, 64, 128)     0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, None, 32, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 32, 128)     16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 32, 64)      8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 32, 32)      2080      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 1024)        0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, None, 800)         4560000   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, None, 800)         3200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, None, 800)         3843200   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, None, 800)         3200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, None, 800)         3843200   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, None, 800)         3200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, None, 800)         3843200   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, None, 800)         3200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, None, 800)         3200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, None, 30)          24030     \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 30)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16249278 (61.99 MB)\n",
      "Trainable params: 16241214 (61.96 MB)\n",
      "Non-trainable params: 8064 (31.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "speech_model = conv_rnn(n_mels, output_dim = output_dim)\n",
    "speech_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output_dim, custom_model, preprocess_model, calc=None):\n",
    "\n",
    "    input_audios = Input(name='the_input', shape=(None,))\n",
    "    pre = preprocess_model(input_audios)\n",
    "    pre = tf.squeeze(pre, [3])\n",
    "\n",
    "    y_pred = custom_model(pre)\n",
    "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
    "    model.output_length = calc\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_builder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None)]            0         \n",
      "                                                                 \n",
      " preprocessin_model (Functi  (None, None, 128, 1)      4         \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOp  (None, None, 128)         0         \n",
      " Lambda)                                                         \n",
      "                                                                 \n",
      " custom_model (Functional)   (None, None, 30)          16249278  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16249282 (61.99 MB)\n",
      "Trainable params: 16241216 (61.96 MB)\n",
      "Non-trainable params: 8066 (31.51 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(output_dim, speech_model, preprocess_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('cnn_rnn3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " the_input (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " preprocessin_model (Functi  (None, None, 128, 1)         4         ['the_input[0][0]']           \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOp  (None, None, 128)            0         ['preprocessin_model[0][0]']  \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " input_length (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " custom_model (Functional)   (None, None, 30)             1624927   ['tf.compat.v1.squeeze[0][0]']\n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)     [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 1)                    0         ['input_length[0][0]']        \n",
      "                                                                                                  \n",
      " label_length (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " ctc (Lambda)                (None, 1)                    0         ['custom_model[0][0]',        \n",
      "                                                                     'the_labels[0][0]',          \n",
      "                                                                     'lambda_1[0][0]',            \n",
      "                                                                     'label_length[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16249282 (61.99 MB)\n",
      "Trainable params: 16241216 (61.96 MB)\n",
      "Non-trainable params: 8066 (31.51 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3304\\1370125407.py:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(generator=data_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/34 [=======>......................] - ETA: 13:03 - loss: 248.2238"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/ctc/CTCLoss' defined at (most recent call last):\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3304\\3744330402.py\", line 4, in <module>\n      train(model, dg, epochs=100)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3304\\1370125407.py\", line 17, in train\n      hist = model.fit_generator(generator=data_gen,\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2810, in fit_generator\n      return self.fit(\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py\", line 212, in call\n      result = self.function(inputs, **kwargs)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3304\\3874367158.py\", line 3, in ctc_lambda_func\n      return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\backend.py\", line 7153, in ctc_batch_cost\n      tf.compat.v1.nn.ctc_loss(\nNode: 'model_1/ctc/CTCLoss'\nLabels length is zero in batch 8\n\t [[{{node model_1/ctc/CTCLoss}}]] [Op:__inference_train_function_40347]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# mlflow.set_experiment('Speech Model-RNN-baseline')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# mlflow.tensorflow.autolog()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m hop_size \u001b[39m=\u001b[39m \u001b[39m512\u001b[39m\n\u001b[1;32m----> 4\u001b[0m train(model, dg, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[41], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model_builder, data_gen, epochs, verbose, optimizer)\u001b[0m\n\u001b[0;32m     14\u001b[0m checkpointer \u001b[39m=\u001b[39m ModelCheckpoint(filepath\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodels/cnn_rnn.h5\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping( monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 17\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(generator\u001b[39m=\u001b[39;49mdata_gen,\n\u001b[0;32m     18\u001b[0m                            epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     19\u001b[0m                            callbacks\u001b[39m=\u001b[39;49m[checkpointer, early_stopping], \n\u001b[0;32m     20\u001b[0m                            verbose\u001b[39m=\u001b[39;49mverbose, \n\u001b[0;32m     21\u001b[0m                            use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     23\u001b[0m \u001b[39m# save model loss\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/models/cnn_rnn.pickle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[1;32md:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2798\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2799\u001b[0m \n\u001b[0;32m   2800\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2801\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2802\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2803\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2804\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2805\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2806\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2807\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2808\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2809\u001b[0m )\n\u001b[1;32m-> 2810\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2811\u001b[0m     generator,\n\u001b[0;32m   2812\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2813\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2814\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2815\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2816\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2817\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2818\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2819\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2820\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2821\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2822\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2823\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2824\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2825\u001b[0m )\n",
      "File \u001b[1;32md:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/ctc/CTCLoss' defined at (most recent call last):\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3304\\3744330402.py\", line 4, in <module>\n      train(model, dg, epochs=100)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3304\\1370125407.py\", line 17, in train\n      hist = model.fit_generator(generator=data_gen,\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2810, in fit_generator\n      return self.fit(\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py\", line 212, in call\n      result = self.function(inputs, **kwargs)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3304\\3874367158.py\", line 3, in ctc_lambda_func\n      return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n    File \"d:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\backend.py\", line 7153, in ctc_batch_cost\n      tf.compat.v1.nn.ctc_loss(\nNode: 'model_1/ctc/CTCLoss'\nLabels length is zero in batch 8\n\t [[{{node model_1/ctc/CTCLoss}}]] [Op:__inference_train_function_40347]"
     ]
    }
   ],
   "source": [
    "# mlflow.set_experiment('Speech Model-RNN-baseline')\n",
    "# mlflow.tensorflow.autolog()\n",
    "hop_size = 512\n",
    "train(model, dg, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_gen,  num_elem=1, index=0):\n",
    "    \n",
    "    pred_data = data_gen.__getitem__(index)\n",
    "\n",
    "    pred_audios = pred_data[0][\"the_input\"]\n",
    "    pred_labels = pred_data[0][\"the_labels\"]\n",
    "    \n",
    "    y_pred = model.predict(pred_audios)\n",
    "\n",
    "    input_shape = tf.keras.backend.shape(y_pred)\n",
    "    input_length = tf.ones(shape=input_shape[0]) * tf.keras.backend.cast(input_shape[1], 'float32')\n",
    "    prediction = tf.keras.backend.ctc_decode(y_pred, input_length, greedy=False)[0][0]\n",
    "    \n",
    "\n",
    "    for i in range(0, num_elem):  # only on clean data\n",
    "        \n",
    "        pred = K.eval(prediction[i]).flatten().tolist()\n",
    "        pred = [i for i in pred if i != -1]\n",
    "\n",
    "\n",
    "\n",
    "        ground_truth = int_sequence_to_text(pred_labels[i].numpy())\n",
    "        hypothesis   = ''.join(int_sequence_to_text(pred))\n",
    "        # error        = wer(ground_truth, hypothesis)\n",
    "                \n",
    "        print('-'*48 + ' ' + str(i) + ' ' + '-'*48)\n",
    "        print('True transcription:\\n' + '\\n' + ground_truth)\n",
    "        print('-'*100)\n",
    "        print('Predicted transcription:\\n' + '\\n' + hypothesis)\n",
    "        # print('-'*100)\n",
    "        # print('Word Error Rate:' + str(error))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows1 = []\n",
    "parent_dir1 = \"./SWH-05-20101107\"\n",
    "files1 = os.listdir(parent_dir1)\n",
    "for f in files1:\n",
    "    audio, fs = librosa.load(f\"{parent_dir1}/{f}\")\n",
    "    filename = f.split('.')[0]\n",
    "    row = {'filename': filename, 'audio': audio}\n",
    "    rows1.append(row)\n",
    "rows1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_audios1 = []\n",
    "for row in rows1:\n",
    "    audio = row['audio']\n",
    "    sample_audios1.append(audio)\n",
    "sample_audios1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('/content/drive/MyDrive/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts1 = []\n",
    "for row in rows1:\n",
    "    filename = row['filename']\n",
    "    filter = meta_df[meta_df['filename'] == filename]\n",
    "    txt = filter[['transcription']].values\n",
    "    txts1.append(txt)\n",
    "\n",
    "txts1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts1 = np.array(txts1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_txts1 = []\n",
    "alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
    "for txt in txts1:\n",
    "    clean_txt = []\n",
    "    for c in txt:\n",
    "        if c not in alphabets and c != ' ':\n",
    "            continue\n",
    "        clean_txt.append(c)\n",
    "    clean_txt = ''.join(clean_txt)\n",
    "    clean_txts1.append(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_txts1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'' in clean_txts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg1 = DataGenerator(sample_audios1[:5], clean_txts1[:5], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(dg1, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
