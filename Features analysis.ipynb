{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from jiwer import wer\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_path = 'data/audio_files/train_audios/'\n",
    "metadata_path = 'data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_faa7312a</td>\n",
       "      <td>audio_faa7312a.mp3</td>\n",
       "      <td>huko kwa Wakiroba Mkoa wa Mara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_643a10c1</td>\n",
       "      <td>audio_643a10c1.mp3</td>\n",
       "      <td>Alingaa katika medani za kisiasa na uongozi nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_5b626e74</td>\n",
       "      <td>audio_5b626e74.mp3</td>\n",
       "      <td>Vitu saba ambavyo kila baba atakuwa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_5972c5f3</td>\n",
       "      <td>audio_5972c5f3.mp3</td>\n",
       "      <td>inaonyesha mawaziri wapya ambao wamechukua naf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_deebd5b0</td>\n",
       "      <td>audio_deebd5b0.mp3</td>\n",
       "      <td>ee hii pia inatumiwa na kiwanda cha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         audio_ID                path  \\\n",
       "0  audio_faa7312a  audio_faa7312a.mp3   \n",
       "1  audio_643a10c1  audio_643a10c1.mp3   \n",
       "2  audio_5b626e74  audio_5b626e74.mp3   \n",
       "3  audio_5972c5f3  audio_5972c5f3.mp3   \n",
       "4  audio_deebd5b0  audio_deebd5b0.mp3   \n",
       "\n",
       "                                            sentence  \n",
       "0                     huko kwa Wakiroba Mkoa wa Mara  \n",
       "1  Alingaa katika medani za kisiasa na uongozi nd...  \n",
       "2               Vitu saba ambavyo kila baba atakuwa.  \n",
       "3  inaonyesha mawaziri wapya ambao wamechukua naf...  \n",
       "4                ee hii pia inatumiwa na kiwanda cha  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(metadata_path)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_e958f59a</td>\n",
       "      <td>wakati wote unatakiwa kuwa mkweli katika maong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_ce644e73</td>\n",
       "      <td>muziki huo alikiambia kipindi cha chagua tano ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_cd6d2100</td>\n",
       "      <td>kuelekea huko bujumbura burundi tutakuwa kunak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_f63c4c05</td>\n",
       "      <td>wataraji kuende na kibarua katika ligi ya mabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_92c7a58b</td>\n",
       "      <td>Kuamua kuondoka nyumbani na kuacha mali yake n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         audio_ID                                           sentence\n",
       "0  audio_e958f59a  wakati wote unatakiwa kuwa mkweli katika maong...\n",
       "1  audio_ce644e73  muziki huo alikiambia kipindi cha chagua tano ...\n",
       "2  audio_cd6d2100  kuelekea huko bujumbura burundi tutakuwa kunak...\n",
       "3  audio_f63c4c05  wataraji kuende na kibarua katika ligi ya mabi...\n",
       "4  audio_92c7a58b  Kuamua kuondoka nyumbani na kuacha mali yake n..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.columns = [\"audio_ID\",\"path\", \"sentence\"]\n",
    "metadata_df = metadata_df[[\"audio_ID\", \"sentence\"]]\n",
    "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19093, 2)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store information about the audio files\n",
    "audio_lengths = []\n",
    "sample_rates = []\n",
    "frequencies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract audio features\n",
    "def extract_audio_features(file_path):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Get the audio length in seconds\n",
    "        audio_length = librosa.get_duration(y=audio, sr=sample_rate)\n",
    "        \n",
    "        # Calculate the dominant frequency using Fourier Transform\n",
    "        fft = np.fft.fft(audio)\n",
    "        frequency = np.argmax(np.abs(fft))\n",
    "        \n",
    "        return audio_length, sample_rate, frequency\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Iterate through all audio files in the directory\n",
    "for filename in os.listdir(wavs_path):\n",
    "    if filename.endswith('.mp3'):\n",
    "        file_path = os.path.join(wavs_path, filename)\n",
    "        audio_length, sample_rate, frequency = extract_audio_features(file_path)\n",
    "        \n",
    "        # Append information to lists\n",
    "        if audio_length is not None:\n",
    "            audio_lengths.append(audio_length)\n",
    "        if sample_rate is not None:\n",
    "            sample_rates.append(sample_rate)\n",
    "        if frequency is not None:\n",
    "            frequencies.append(frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files loaded: 19093\n",
      "Average audio length: 5.40 seconds\n",
      "Maximum audio length: 20.09 seconds\n",
      "Minimum audio length: 1.26 seconds\n",
      "Average sample rate: 32000.00 Hz\n",
      "Maximum dominant frequency: 632949 Hz\n",
      "Minimum dominant frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display statistics\n",
    "num_audios = len(audio_lengths)\n",
    "avg_audio_length = np.mean(audio_lengths)\n",
    "max_audio_length = np.max(audio_lengths)\n",
    "min_audio_length = np.min(audio_lengths)\n",
    "\n",
    "avg_sample_rate = np.mean(sample_rates)\n",
    "max_frequency = np.max(frequencies)\n",
    "min_frequency = np.min(frequencies)\n",
    "\n",
    "print(f\"Number of audio files loaded: {num_audios}\")\n",
    "print(f\"Average audio length: {avg_audio_length:.2f} seconds\")\n",
    "print(f\"Maximum audio length: {max_audio_length:.2f} seconds\")\n",
    "print(f\"Minimum audio length: {min_audio_length:.2f} seconds\")\n",
    "\n",
    "print(f\"Average sample rate: {avg_sample_rate:.2f} Hz\")\n",
    "print(f\"Maximum dominant frequency: {max_frequency} Hz\")\n",
    "print(f\"Minimum dominant frequency: {min_frequency} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a histogram of audio lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(audio_lengths, bins=30, color='blue', alpha=0.7)\n",
    "plt.xlabel('Audio Length (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Audio Lengths')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                File Name  Audio Length (seconds)  Dominant Frequency\n",
      "0      audio_0001945d.mp3                   9.576         1426.060524\n",
      "1      audio_0002ac69.mp3                   7.560         1246.220745\n",
      "2      audio_00070400.mp3                   4.536         1074.869688\n",
      "3      audio_0009db0f.mp3                   7.056         1476.977876\n",
      "4      audio_000dddec.mp3                   2.916         1335.745604\n",
      "...                   ...                     ...                 ...\n",
      "19088  audio_fff29979.mp3                   7.704         1622.178135\n",
      "19089  audio_fff306b8.mp3                   7.668         1077.812153\n",
      "19090  audio_fff8e690.mp3                   8.640         1402.524821\n",
      "19091  audio_fffc8a20.mp3                   7.956         1231.751479\n",
      "19092  audio_ffffeeb1.mp3                   2.988         1508.134797\n",
      "\n",
      "[19093 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store information about the audio files\n",
    "audio_data = []\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_audio_features(file_path):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Get the audio length in seconds\n",
    "        audio_length = librosa.get_duration(y=audio, sr=sample_rate)\n",
    "        \n",
    "        # Calculate the dominant frequency using Fourier Transform\n",
    "        fft = abs(librosa.stft(audio))\n",
    "        frequency = librosa.feature.spectral_centroid(S=fft).mean()\n",
    "        \n",
    "        return audio_length, frequency\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Iterate through all audio files in the directory\n",
    "for filename in os.listdir(wavs_path):\n",
    "    if filename.endswith('.mp3'):\n",
    "        file_path = os.path.join(wavs_path, filename)\n",
    "        audio_length, frequency = extract_audio_features(file_path)\n",
    "        \n",
    "        # Append information to the list\n",
    "        if audio_length is not None and frequency is not None:\n",
    "            audio_data.append([filename, audio_length, frequency])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(audio_data, columns=['File Name', 'Audio Length (seconds)', 'Dominant Frequency'])\n",
    "\n",
    "# print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Audio Length (seconds)</th>\n",
       "      <th>Dominant Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_0001945d.mp3</td>\n",
       "      <td>9.576</td>\n",
       "      <td>1426.060524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_0002ac69.mp3</td>\n",
       "      <td>7.560</td>\n",
       "      <td>1246.220745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_00070400.mp3</td>\n",
       "      <td>4.536</td>\n",
       "      <td>1074.869688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_0009db0f.mp3</td>\n",
       "      <td>7.056</td>\n",
       "      <td>1476.977876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_000dddec.mp3</td>\n",
       "      <td>2.916</td>\n",
       "      <td>1335.745604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            File Name  Audio Length (seconds)  Dominant Frequency\n",
       "0  audio_0001945d.mp3                   9.576         1426.060524\n",
       "1  audio_0002ac69.mp3                   7.560         1246.220745\n",
       "2  audio_00070400.mp3                   4.536         1074.869688\n",
       "3  audio_0009db0f.mp3                   7.056         1476.977876\n",
       "4  audio_000dddec.mp3                   2.916         1335.745604"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File Name                 19093\n",
       "Audio Length (seconds)      256\n",
       "Dominant Frequency        19093\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.head(300).to_csv('data/notebook - 1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('data/notebook - 1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 240\n",
      "Size of validation set: 60\n"
     ]
    }
   ],
   "source": [
    "# splitting into training and validation data.\n",
    "\n",
    "split = int(len(metadata_df) * 0.8 )\n",
    "split2 = int(len(metadata_df) * 0.2 )\n",
    "train_df = metadata_df[:split]\n",
    "df_val = metadata_df[split:]\n",
    "\n",
    "print(f\"Size of training set: {len(train_df)}\")\n",
    "print(f\"Size of validation set: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_d43074e0</td>\n",
       "      <td>zao za Dar es Salaam na Nairobi mwaka elfumoja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_2382f7f1</td>\n",
       "      <td>Wuasinkishu Siria Laitayiok Loitai Kisonko Mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_f99426d9</td>\n",
       "      <td>miti mingi hudondosha majani yake na maua hutokea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_dc0c00a3</td>\n",
       "      <td>Iwe dawa ya kosa langu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_409014fd</td>\n",
       "      <td>Wawakilishi wa makoloni yote kumi na tatu waka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         audio_ID                                           sentence\n",
       "0  audio_d43074e0  zao za Dar es Salaam na Nairobi mwaka elfumoja...\n",
       "1  audio_2382f7f1  Wuasinkishu Siria Laitayiok Loitai Kisonko Mat...\n",
       "2  audio_f99426d9  miti mingi hudondosha majani yake na maua hutokea\n",
       "3  audio_dc0c00a3                             Iwe dawa ya kosa langu\n",
       "4  audio_409014fd  Wawakilishi wa makoloni yote kumi na tatu waka..."
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>audio_0706d283</td>\n",
       "      <td>chembe za umeme katika shughuli tofauti za viw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>audio_9ba8ab32</td>\n",
       "      <td>inayotumika kuwaondoa viongozi madarakani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>audio_fb63e65a</td>\n",
       "      <td>kakar anadokeza kuwa ufafanuzi wa kimataifa wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>audio_c1784e96</td>\n",
       "      <td>ni shabaha kwa maendeleo ya Gold Coast Lakini ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>audio_28d6ea43</td>\n",
       "      <td>na kwa umri wangu na kwa uzoefu wangu wa mji huu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           audio_ID                                           sentence\n",
       "240  audio_0706d283  chembe za umeme katika shughuli tofauti za viw...\n",
       "241  audio_9ba8ab32          inayotumika kuwaondoa viongozi madarakani\n",
       "242  audio_fb63e65a  kakar anadokeza kuwa ufafanuzi wa kimataifa wa...\n",
       "243  audio_c1784e96  ni shabaha kwa maendeleo ya Gold Coast Lakini ...\n",
       "244  audio_28d6ea43   na kwa umri wangu na kwa uzoefu wangu wa mji huu"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is : ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', ' '](size is : 31)\n"
     ]
    }
   ],
   "source": [
    "# The set of characters accepted in the sentence\n",
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "\n",
    "# mapping characters to integers.\n",
    "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token='')\n",
    "# Mapping integers back to original characters.\n",
    "num_to_char = keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is : {char_to_num.get_vocabulary()}\"\n",
    "    f\"(size is : {char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.preprocessing.string_lookup.StringLookup at 0x2a83d136a60>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An integer scalar Tensor. The window length in samples.\n",
    "frame_length = 256\n",
    "# An integer scalar Tensor. The number of samples to step.\n",
    "frame_step = 160\n",
    "# An integer scalar Tensor , The size of the FFT to apply.\n",
    "# If not provided , uses the smallest power of 2 enclosing frame lenght.\n",
    "fft_length = 384\n",
    "\n",
    "def encode_single_sample(wav_file, label):\n",
    "    ## Process the audio.\n",
    "    file = tf.io.read_file(wavs_path + wav_file + \".wav\")\n",
    "\n",
    "    ## Decode the audio file\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    ## Change type to float.\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    ## Get the spectrogram\n",
    "    spectrogram = tf.signal.stft(\n",
    "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
    "    )\n",
    "\n",
    "    ## We only need the magnitude which can be derived by applying tf.abs\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "\n",
    "    ## normalization.\n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "\n",
    "    ## Process the label\n",
    "    ## Convert the label to lower case.\n",
    "    label = tf.strings.lower(label)\n",
    "    ## split the label\n",
    "    label = tf.strings.unicode_split(label, input_encoding='UTF-8')\n",
    "    ## Map the characters in label to numbers.\n",
    "    label = char_to_num(label)\n",
    "    # Return a dict as our model is expecting two inputs.\n",
    "    return spectrogram, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Define the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(train_df[\"audio_ID\"]), list(train_df[\"sentence\"]))\n",
    "\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Define the validation dataset.\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_val[\"audio_ID\"]), list(df_val[\"sentence\"]))\n",
    ")\n",
    "\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss_value\n",
    "    \n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepSpeech_2\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                                    Output Shape                                Param #          \n",
      "==============================================================================================================\n",
      " input (InputLayer)                              [(None, None, 193)]                         0                \n",
      "                                                                                                              \n",
      " expand_dim (Reshape)                            (None, None, 193, 1)                        0                \n",
      "                                                                                                              \n",
      " conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n",
      "                                                                                                              \n",
      " conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n",
      "                                                                                                              \n",
      " conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n",
      "                                                                                                              \n",
      " conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n",
      "                                                                                                              \n",
      " reshape_6 (Reshape)                             (None, None, 1568)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional)                 (None, None, 1024)                          6395904          \n",
      "                                                                                                              \n",
      " dropout_30 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_2 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_31 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_3 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_32 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_4 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_33 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_5 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dense_1 (Dense)                                 (None, None, 1024)                          1049600          \n",
      "                                                                                                              \n",
      " dense_1_relu (ReLU)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dropout_34 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dense_6 (Dense)                                 (None, None, 32)                            32800            \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 26628480 (101.58 MB)\n",
      "Trainable params: 26628352 (101.58 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
    "    \n",
    "    ## Model similar to DeepSpeech2.\n",
    "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
    "    ## Expand the dimension to use 2D CNN\n",
    "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
    "\n",
    "    ## Convolution layer 1\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11,41],\n",
    "        strides=[2, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_1\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
    "\n",
    "    ## Convolution layer 2\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11, 21],\n",
    "        strides=[1,2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_2\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
    "    # Reshape the resulted volume to feed the RNNs layers.\n",
    "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
    "    # RNN Layers.\n",
    "    for i in range(1, rnn_layers + 1):\n",
    "        recurrent = layers.GRU(\n",
    "            units=rnn_units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            use_bias=True,\n",
    "            return_sequences=True,\n",
    "            reset_after=True,\n",
    "            name=f\"gru_{i}\",\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
    "        )(x)\n",
    "        if i < rnn_layers:\n",
    "            x = layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "    # Dense layer.\n",
    "    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
    "    x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
    "    x = layers.Dropout(rate=0.5)(x)\n",
    "    # Classification layer.\n",
    "    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
    "    # Model\n",
    "    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
    "    # Optimizer.\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    # Compile the model and return\n",
    "    model.compile(optimizer=opt, loss=CTCLoss)\n",
    "    return model\n",
    "\n",
    "# Get the model.\n",
    "model = build_model(\n",
    "    input_dim=fft_length // 2 + 1,\n",
    "    output_dim=char_to_num.vocabulary_size(),\n",
    "    rnn_units=512,\n",
    ")\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0] * pred.shape[1])\n",
    "    # Use_greedy search\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    ## Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode('utf-8')\n",
    "        output_text.append(result)\n",
    "    return output_text\n",
    "\n",
    "## A callback class to output a few transcription during training.\n",
    "class CallbackEval(keras.callbacks.Callback):\n",
    "    ## Display a batch of outputs after every epoch.\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in self.dataset:\n",
    "            X, y = batch\n",
    "            batch_predictions = model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y:\n",
    "                label = (\n",
    "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode('utf-8')\n",
    "                )\n",
    "                targets.append(label)\n",
    "\n",
    "        wer_score = wer(targets, predictions)\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        for i in np.random.randint(0, len(predictions), 2):\n",
    "            print(f\"Target    : {targets[i]}\")\n",
    "            print(f\"Prediction: {predictions[i]}\")\n",
    "            print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nNewRandomAccessFile failed to Create/Open: audio_files/train_wavs/audio_d43074e0.wav : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_183882]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[320], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m validation_callback \u001b[39m=\u001b[39m CallbackEval(validation_dataset)\n\u001b[0;32m      5\u001b[0m \u001b[39m## Train the model.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      7\u001b[0m     train_dataset,\n\u001b[0;32m      8\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_dataset,\n\u001b[0;32m      9\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     10\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[validation_callback],\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m     )\n",
      "File \u001b[1;32md:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Projects\\Hackathons\\AI4D ASR Challenge\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nNewRandomAccessFile failed to Create/Open: audio_files/train_wavs/audio_d43074e0.wav : The system cannot find the file specified.\r\n; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_183882]"
     ]
    }
   ],
   "source": [
    "## Lets start training.\n",
    "epochs = 2\n",
    "## CallBack function to check sentence in validation set.\n",
    "validation_callback = CallbackEval(validation_dataset)\n",
    "## Train the model.\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[validation_callback],\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us check the results on the validation samples.\n",
    "predictions = []\n",
    "targets = []\n",
    "for batch in validation_dataset:\n",
    "    X, y = batch\n",
    "    batch_predictions = model.predict(X)\n",
    "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "    predictions.extend(batch_predictions)\n",
    "    for label in y:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        targets.append(label)\n",
    "wer_score = wer(targets, predictions)\n",
    "print(\"-\" * 100)\n",
    "print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "print(\"-\" * 100)\n",
    "for i in np.random.randint(0, len(predictions), 5):\n",
    "        print(f\"Target    : {targets[i]}\")\n",
    "        print(f\"Prediction: {predictions[i]}\")\n",
    "        print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
