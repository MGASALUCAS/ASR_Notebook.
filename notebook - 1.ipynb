{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Drive Setup!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd MachineLearning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ASR challenge/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# import librosa\n",
    "# import pandas as pd\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# from IPython.display import Audio\n",
    "\n",
    "# import librosa.display\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.layers import * \n",
    "# from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from IPython import display\n",
    "# from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Csv data and Audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Converting mp3 to wavs files.\n",
    "\n",
    "# from pydub import AudioSegment\n",
    "# import os\n",
    "\n",
    "# # Set the paths for input MP3 files and output WAV files.\n",
    "# input_folder = \"/data/audio_files/train_audios/\"\n",
    "# output_folder = \"train_wavs/\"\n",
    "\n",
    "# # Ensure the output folder exists, create it if not.\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Convert MP3 to WAV function\n",
    "# def convert_mp3_to_wav(mp3_path, wav_path):\n",
    "#     sound = AudioSegment.from_mp3(mp3_path)\n",
    "#     sound.export(wav_path, format=\"wav\")\n",
    "\n",
    "# # Iterate through MP3 files in the input folder and convert to WAV.\n",
    "# for mp3_file in os.listdir(input_folder):\n",
    "#     if mp3_file.endswith(\".mp3\"):\n",
    "#         mp3_path = os.path.join(input_folder, mp3_file)\n",
    "#         wav_file = os.path.splitext(mp3_file)[0] + \".wav\"\n",
    "#         wav_path = os.path.join(output_folder, wav_file)\n",
    "#         convert_mp3_to_wav(mp3_path, wav_path)\n",
    "#         print(f\"Converted {mp3_file} to {wav_file}\")\n",
    "\n",
    "# print(\"Conversion completed!.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_path = 'data/audio_files/train_audios/'\n",
    "metadata_path = 'data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(metadata_path)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_faa7312a</td>\n",
       "      <td>huko kwa Wakiroba Mkoa wa Mara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_643a10c1</td>\n",
       "      <td>Alingaa katika medani za kisiasa na uongozi nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_5b626e74</td>\n",
       "      <td>Vitu saba ambavyo kila baba atakuwa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_5972c5f3</td>\n",
       "      <td>inaonyesha mawaziri wapya ambao wamechukua naf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_deebd5b0</td>\n",
       "      <td>ee hii pia inatumiwa na kiwanda cha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         audio_ID                                           sentence\n",
       "0  audio_faa7312a                     huko kwa Wakiroba Mkoa wa Mara\n",
       "1  audio_643a10c1  Alingaa katika medani za kisiasa na uongozi nd...\n",
       "2  audio_5b626e74               Vitu saba ambavyo kila baba atakuwa.\n",
       "3  audio_5972c5f3  inaonyesha mawaziri wapya ambao wamechukua naf...\n",
       "4  audio_deebd5b0                ee hii pia inatumiwa na kiwanda cha"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
    "metadata_df = metadata_df[[\"audio_ID\", \"sentence\"]]\n",
    "# metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19093, 2)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the size of data used to reduce training time and automatically create new dataframe.\n",
    "\n",
    "metadata_df.head(1200).to_csv('data/notebook - 1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('data/notebook - 1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 160\n",
      "Size of validation set: 40\n"
     ]
    }
   ],
   "source": [
    "# splitting into training and validation data.\n",
    "\n",
    "split = int(len(metadata_df) * 0.90 )\n",
    "# split2 = int(len(metadata_df) * 0.2 )\n",
    "train_df = metadata_df[:split]\n",
    "df_val = metadata_df[split:]\n",
    "\n",
    "print(f\"Size of training set: {len(train_df)}\")\n",
    "print(f\"Size of validation set: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_faa7312a</td>\n",
       "      <td>huko kwa Wakiroba Mkoa wa Mara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_643a10c1</td>\n",
       "      <td>Alingaa katika medani za kisiasa na uongozi nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_5b626e74</td>\n",
       "      <td>Vitu saba ambavyo kila baba atakuwa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_5972c5f3</td>\n",
       "      <td>inaonyesha mawaziri wapya ambao wamechukua naf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_deebd5b0</td>\n",
       "      <td>ee hii pia inatumiwa na kiwanda cha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         audio_ID                                           sentence\n",
       "0  audio_faa7312a                     huko kwa Wakiroba Mkoa wa Mara\n",
       "1  audio_643a10c1  Alingaa katika medani za kisiasa na uongozi nd...\n",
       "2  audio_5b626e74               Vitu saba ambavyo kila baba atakuwa.\n",
       "3  audio_5972c5f3  inaonyesha mawaziri wapya ambao wamechukua naf...\n",
       "4  audio_deebd5b0                ee hii pia inatumiwa na kiwanda cha"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_ID</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>audio_e8c36596</td>\n",
       "      <td>hasa barani afrika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>audio_cfd5f18f</td>\n",
       "      <td>mwandishi wetu zuhra mwera ametuandalia taarif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>audio_26d8c981</td>\n",
       "      <td>Wakristo wakiwemo Waprotestanti na Wakatoliki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>audio_b4cca469</td>\n",
       "      <td>Serikali imebainisha majukumu ya mamlaka mbali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>audio_ce851761</td>\n",
       "      <td>Nyumba imejengwa.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           audio_ID                                           sentence\n",
       "160  audio_e8c36596                                 hasa barani afrika\n",
       "161  audio_cfd5f18f  mwandishi wetu zuhra mwera ametuandalia taarif...\n",
       "162  audio_26d8c981  Wakristo wakiwemo Waprotestanti na Wakatoliki ...\n",
       "163  audio_b4cca469  Serikali imebainisha majukumu ya mamlaka mbali...\n",
       "164  audio_ce851761                                  Nyumba imejengwa."
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### change characters to integers and integers to charaters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is : ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', ' '](size is : 31)\n"
     ]
    }
   ],
   "source": [
    "# The set of characters accepted in the sentence\n",
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "\n",
    "# mapping characters to integers.\n",
    "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token='')\n",
    "# Mapping integers back to original characters.\n",
    "num_to_char = keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is : {char_to_num.get_vocabulary()}\"\n",
    "    f\"(size is : {char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An integer scalar Tensor. The window length in samples.\n",
    "frame_length = 256\n",
    "# An integer scalar Tensor. The number of samples to step.\n",
    "frame_step = 160\n",
    "# An integer scalar Tensor , The size of the FFT to apply.\n",
    "# If not provided , uses the smallest power of 2 enclosing frame lenght.\n",
    "fft_length = 384\n",
    "\n",
    "def encode_single_sample(wav_file, label):\n",
    "    ## Process the audio.\n",
    "    ## Read the audio file.\n",
    "    file = tf.io.read_file(wavs_path + wav_file + \".wav\")\n",
    "\n",
    "    ## Decode the audio file\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    ## Change type to float.\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    ## Get the spectrogram\n",
    "    spectrogram = tf.signal.stft(\n",
    "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
    "    )\n",
    "\n",
    "    ## We only need the magnitude which can be derived by applying tf.abs\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "\n",
    "    ## normalization.\n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "\n",
    "    ## Process the label\n",
    "    ## Convert the label to lower case.\n",
    "    label = tf.strings.lower(label)\n",
    "    ## split the label\n",
    "    label = tf.strings.unicode_split(label, input_encoding='UTF-8')\n",
    "    ## Map the characters in label to numbers.\n",
    "    label = char_to_num(label)\n",
    "    # Return a dict as our model is expecting two inputs.\n",
    "    return spectrogram, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Define the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(train_df[\"audio_ID\"]), list(train_df[\"sentence\"]))\n",
    "\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Define the validation dataset.\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_val[\"audio_ID\"]), list(df_val[\"sentence\"]))\n",
    ")\n",
    "\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTC Loss Function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for time and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss_value\n",
    "    \n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepSpeech_2\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                                    Output Shape                                Param #          \n",
      "==============================================================================================================\n",
      " input (InputLayer)                              [(None, None, 193)]                         0                \n",
      "                                                                                                              \n",
      " expand_dim (Reshape)                            (None, None, 193, 1)                        0                \n",
      "                                                                                                              \n",
      " conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n",
      "                                                                                                              \n",
      " conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n",
      "                                                                                                              \n",
      " conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n",
      "                                                                                                              \n",
      " conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n",
      "                                                                                                              \n",
      " reshape_6 (Reshape)                             (None, None, 1568)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional)                 (None, None, 1024)                          6395904          \n",
      "                                                                                                              \n",
      " dropout_30 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_2 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_31 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_3 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_32 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_4 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_33 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_5 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dense_1 (Dense)                                 (None, None, 1024)                          1049600          \n",
      "                                                                                                              \n",
      " dense_1_relu (ReLU)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dropout_34 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dense_6 (Dense)                                 (None, None, 32)                            32800            \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 26628480 (101.58 MB)\n",
      "Trainable params: 26628352 (101.58 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
    "    \n",
    "    ## Model similar to DeepSpeech2.\n",
    "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
    "    ## Expand the dimension to use 2D CNN\n",
    "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
    "\n",
    "    ## Convolution layer 1\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11,41],\n",
    "        strides=[2, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_1\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
    "\n",
    "    ## Convolution layer 2\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11, 21],\n",
    "        strides=[1,2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_2\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
    "    # Reshape the resulted volume to feed the RNNs layers.\n",
    "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
    "    # RNN Layers.\n",
    "    for i in range(1, rnn_layers + 1):\n",
    "        recurrent = layers.GRU(\n",
    "            units=rnn_units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            use_bias=True,\n",
    "            return_sequences=True,\n",
    "            reset_after=True,\n",
    "            name=f'gru_{i}',\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\",\n",
    "        )(x)\n",
    "        if i < rnn_layers:\n",
    "            x = layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "    # Dense layer.\n",
    "    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
    "    x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
    "    x = layers.Dropout(rate=0.5)(x)\n",
    "    # Classification layer.\n",
    "    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
    "    # Model\n",
    "    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
    "    # Optimizer.\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    # Compile the model and return\n",
    "    model.compile(optimizer=opt, loss=CTCLoss)\n",
    "    return model\n",
    "\n",
    "# Get the model.\n",
    "model = build_model(\n",
    "    input_dim=fft_length // 2 + 1,\n",
    "    output_dim=char_to_num.vocabulary_size(),\n",
    "    rnn_units=512,\n",
    ")\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0] * pred.shape[1])\n",
    "    # Use_greedy search\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    ## Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode('utf-8')\n",
    "        output_text.append(result)\n",
    "    return output_text\n",
    "\n",
    "## A callback class to output a few transcription during training.\n",
    "class CallbackEval(keras.callbacks.Callback):\n",
    "    ## Display a batch of outputs after every epoch.\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in self.dataset:\n",
    "            X, y = batch\n",
    "            batch_predictions = model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y:\n",
    "                label = (\n",
    "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode('utf-8')\n",
    "                )\n",
    "                targets.append(label)\n",
    "\n",
    "        wer_score = wer(targets, predictions)\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        for i in np.random.randint(0, len(predictions), 2):\n",
    "            print(f\"Target    : {targets[i]}\")\n",
    "            print(f\"Prediction: {predictions[i]}\")\n",
    "            print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets start training.\n",
    "epochs = 1\n",
    "## CallBack function to check sentence in validation set.\n",
    "validation_callback = CallbackEval(validation_dataset)\n",
    "## Train the model.\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[validation_callback],\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us check the results on the validation samples.\n",
    "predictions = []\n",
    "targets = []\n",
    "for batch in validation_dataset:\n",
    "    X, y = batch\n",
    "    batch_predictions = model.predict(X)\n",
    "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "    predictions.extend(batch_predictions)\n",
    "    for label in y:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        targets.append(label)\n",
    "wer_score = wer(targets, predictions)\n",
    "print(\"-\" * 100)\n",
    "print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "print(\"-\" * 100)\n",
    "for i in np.random.randint(0, len(predictions), 5):\n",
    "        print(f\"Target    : {targets[i]}\")\n",
    "        print(f\"Prediction: {predictions[i]}\")\n",
    "        print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
