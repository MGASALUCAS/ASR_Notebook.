{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jER89k3gSjLk",
        "outputId": "0a076864-9024-487e-ecc8-9dcfa12c0f85"
      },
      "outputs": [],
      "source": [
        "!pip install huggingsound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh5y2TBEc7nF",
        "outputId": "f4cee2ba-b277-4ccf-8111-659090eb89af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:huggingsound.speech_recognition.model:Loading model...\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "WARNING:root:bos_token <s> not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:eos_token </s> not in provided tokens. It will be added to the list of tokens\n",
            "100%|██████████| 2/2 [00:08<00:00,  4.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'transcription': 'atakuwa na mambo mawili ya kukabiliana nayo', 'start_timestamps': [520, 600, 640, 780, 820, 900, 940, 980, 1060, 1080, 1100, 1200, 1260, 1360, 1380, 1420, 1460, 1540, 1580, 1680, 1740, 1860, 1900, 1920, 1960, 2000, 2020, 2100, 2120, 2220, 2260, 2380, 2400, 2520, 2540, 2640, 2740, 2760, 2800, 2880, 2940, 3100, 3140], 'end_timestamps': [540, 620, 660, 800, 840, 920, 960, 1000, 1080, 1100, 1120, 1220, 1280, 1380, 1400, 1440, 1480, 1560, 1600, 1700, 1760, 1880, 1920, 1940, 1980, 2020, 2040, 2120, 2140, 2240, 2280, 2400, 2420, 2540, 2560, 2660, 2760, 2780, 2820, 2900, 2960, 3120, 3160], 'probabilities': [0.998897910118103, 0.9996330738067627, 0.999882698059082, 0.9997827410697937, 0.999816358089447, 0.9944215416908264, 0.9999090433120728, 0.9998611211776733, 0.9997653365135193, 0.9999184608459473, 0.8238128423690796, 0.999818742275238, 0.9998225569725037, 0.9998531341552734, 0.9854356646537781, 0.9998458623886108, 0.999919056892395, 0.9998569488525391, 0.9998936653137207, 0.9966741800308228, 0.9935582280158997, 0.9998626708984375, 0.9998847246170044, 0.9994271993637085, 0.997658371925354, 0.9998095631599426, 0.9857235550880432, 0.999671459197998, 0.9992503523826599, 0.9998220801353455, 0.9998637437820435, 0.9988365769386292, 0.9998295307159424, 0.9997857213020325, 0.999786913394928, 0.999889612197876, 0.9998003840446472, 0.9985106587409973, 0.9999051094055176, 0.9995132684707642, 0.9998036026954651, 0.9976832866668701, 0.9994900226593018]}, {'transcription': 'waandaa meza mbele yangu', 'start_timestamps': [340, 380, 500, 600, 640, 680, 780, 800, 900, 960, 1060, 1100, 1140, 1200, 1220, 1260, 1360, 1400, 1420, 1460, 1500, 1640, 1660, 1700], 'end_timestamps': [360, 400, 520, 620, 660, 700, 800, 820, 920, 980, 1080, 1120, 1160, 1220, 1240, 1280, 1380, 1420, 1440, 1480, 1520, 1660, 1680, 1720], 'probabilities': [0.9998239874839783, 0.9998849630355835, 0.9999043941497803, 0.9998660087585449, 0.9996305704116821, 0.9999048709869385, 0.9998513460159302, 0.9997579455375671, 0.9996945858001709, 0.9998667240142822, 0.9995373487472534, 0.9998986721038818, 0.9999204874038696, 0.9998844861984253, 0.9997918009757996, 0.9998464584350586, 0.9998067021369934, 0.999690055847168, 0.9999305009841919, 0.9998524188995361, 0.9995450377464294, 0.9998468160629272, 0.8661497235298157, 0.9998825788497925]}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from huggingsound import SpeechRecognitionModel\n",
        "\n",
        "model = SpeechRecognitionModel(\"Akashpb13/Swahili_xlsr\")\n",
        "audio_paths = [\"audio_00b84616.mp3\", \"audio_0a0f9147.mp3\"]\n",
        "\n",
        "transcriptions = model.transcribe(audio_paths)\n",
        "\n",
        "print(transcriptions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhOLuUNipao2",
        "outputId": "5794b5b4-84ce-4def-fd6a-c8b81976e362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3oFE19EpfM6",
        "outputId": "2cb6963a-4368-46e1-cfba-eadc75e3ace5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ]
        }
      ],
      "source": [
        "cd drive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EErLDZrpjJC",
        "outputId": "502dd82b-a627-413b-fdfd-fb9cf999743c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBTNN4UTpll7",
        "outputId": "f8c6b8e7-eb62-45a9-e201-3bcb7dedf1f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MachineLearning\n"
          ]
        }
      ],
      "source": [
        "cd MachineLearning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsuyIL69poQ-",
        "outputId": "b5cce0b6-ef4a-4204-c375-82b587d8c633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MachineLearning/Data\n"
          ]
        }
      ],
      "source": [
        "cd Data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Kcude6OuEBe",
        "outputId": "ccf8ae10-cfef-4f80-eb49-c03eea55925e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MachineLearning/Data/ASR challenge\n"
          ]
        }
      ],
      "source": [
        "cd ASR challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEwRHiwzuJMp",
        "outputId": "2d99ab4e-70e9-4e37-e47a-4e1d6e8bb9e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "colab_book.ipynb      test_audios.zip       \u001b[0m\u001b[01;34mtrain_wavs\u001b[0m/\n",
            "notebook1.ipynb       test.csv              Untitled0.ipynb\n",
            "notebook2.ipynb       \u001b[01;34mtrain\u001b[0m/                Untitledagain.ipynb\n",
            "notebook3.ipynb       \u001b[01;34mtrain_audios\u001b[0m/         VariableDefinitions.csv\n",
            "SampleSubmission.csv  train_audios.zip      vocab.json\n",
            "submission5.csv       train.csv             wav2vector.ipynb\n",
            "\u001b[01;34mtest\u001b[0m/                 trained_asr_model.h5  \u001b[01;34mwavs\u001b[0m/\n",
            "\u001b[01;34mtest_audios\u001b[0m/          TrainedModel.h5\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "hjwtUBSHu7dx",
        "outputId": "4e26ce05-583a-46ca-a17b-5e54cb40c1dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5858861b-1aeb-469e-9b50-8254d7c012b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_ID</th>\n",
              "      <th>path</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>audio_3e7df4e9</td>\n",
              "      <td>audio_3e7df4e9.mp3</td>\n",
              "      <td>Tarime Rorya hao ni Wakurya wa kaskazini Mara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>audio_0596ad2a</td>\n",
              "      <td>audio_0596ad2a.mp3</td>\n",
              "      <td>li hili ningependa nikuulize bukuku</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>audio_7bde792a</td>\n",
              "      <td>audio_7bde792a.mp3</td>\n",
              "      <td>ambayo yamepangwa utekelezaji wake kukamilika ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5858861b-1aeb-469e-9b50-8254d7c012b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5858861b-1aeb-469e-9b50-8254d7c012b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5858861b-1aeb-469e-9b50-8254d7c012b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b61bcafc-e51e-4902-b4d8-037cc419560a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b61bcafc-e51e-4902-b4d8-037cc419560a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b61bcafc-e51e-4902-b4d8-037cc419560a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         audio_ID                path  \\\n",
              "0  audio_3e7df4e9  audio_3e7df4e9.mp3   \n",
              "1  audio_0596ad2a  audio_0596ad2a.mp3   \n",
              "2  audio_7bde792a  audio_7bde792a.mp3   \n",
              "\n",
              "                                            sentence  \n",
              "0      Tarime Rorya hao ni Wakurya wa kaskazini Mara  \n",
              "1                li hili ningependa nikuulize bukuku  \n",
              "2  ambayo yamepangwa utekelezaji wake kukamilika ...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_path = 'train_audios/train_audios/'\n",
        "metadata_path =  \"train.csv\"\n",
        "\n",
        "import pandas as pd\n",
        "# Read metadata file and parse it\n",
        "metadata_df = pd.read_csv(metadata_path)\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "metadata_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCZhRmNHvb6d",
        "outputId": "5c6e8310-a703-417e-ec30-a52860593597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the training set: 1909\n",
            "Size of the training set: 382\n"
          ]
        }
      ],
      "source": [
        "split = int(len(metadata_df) * 0.1)\n",
        "split_= int(len(metadata_df) * 0.98)\n",
        "df_train = metadata_df[:split]\n",
        "df_val = metadata_df[split_:]\n",
        "\n",
        "print(f\"Size of the training set: {len(df_train)}\")\n",
        "print(f\"Size of the training set: {len(df_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xG8I8OE8vVNV"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "# Define the training dataset\n",
        "import tensorflow as tf\n",
        "train_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_train[\"path\"]), list(df_train[\"sentence\"]))\n",
        ")\n",
        "# train_data = (\n",
        "#     train_data.map(num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#     .padded_batch(batch_size)\n",
        "#     .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "# )\n",
        "\n",
        "# Define the validation dataset\n",
        "eval_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_val[\"path\"]), list(df_val[\"sentence\"]))\n",
        ")\n",
        "# eval_data = (\n",
        "#     eval_data.map(num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#     .padded_batch(batch_size)\n",
        "#     .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "1459de2e8114415982780e03ddeab798",
            "8e99c93415034918b482f02bd9d47634",
            "63916d984a354b1da384c4b19a1d01c3",
            "cef77c56f7e74a3090ac1a5086bc694e"
          ]
        },
        "id": "YvknYAADhCdS",
        "outputId": "5a6da65c-bcf3-42b0-f808-94b3b9c55cb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:huggingsound.speech_recognition.model:Loading model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1459de2e8114415982780e03ddeab798",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e99c93415034918b482f02bd9d47634",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63916d984a354b1da384c4b19a1d01c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)rocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
            "  warnings.warn(\n",
            "WARNING:huggingsound.speech_recognition.model:Not fine-tuned model! You'll need to fine-tune it before use this model for audio transcription\n",
            "WARNING:root:blank_token <pad> not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:silence_token | not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:unk_token <unk> not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:bos_token <s> not in provided tokens. It will be added to the list of tokens\n",
            "WARNING:root:eos_token </s> not in provided tokens. It will be added to the list of tokens\n",
            "`use_fast` is set to `True` but the tokenizer class does not have a fast version.  Falling back to the slow version.\n",
            "INFO:huggingsound.speech_recognition.model:Loading training data...\n",
            "INFO:huggingsound.speech_recognition.model:Converting data format...\n",
            "INFO:huggingsound.speech_recognition.model:Preparing data input and labels...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cef77c56f7e74a3090ac1a5086bc694e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/17184 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingsound import TrainingArguments, ModelArguments, SpeechRecognitionModel, TokenSet\n",
        "\n",
        "model = SpeechRecognitionModel(\"Akashpb13/Swahili_xlsr\")\n",
        "output_dir = \"my/finetuned/model/output/dir\"\n",
        "\n",
        "# first of all, you need to define your model's token set\n",
        "# however, the token set is only needed for non-finetuned models\n",
        "# if you pass a new token set for an already finetuned model, it'll be ignored during training\n",
        "tokens = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"'\"]\n",
        "token_set = TokenSet(tokens)\n",
        "\n",
        "\n",
        "# and finally, fine-tune your model\n",
        "model.finetune(\n",
        "    output_dir,\n",
        "    train_data=train_data,\n",
        "    eval_data=eval_data, # the eval_data is optional\n",
        "    token_set=token_set,\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
